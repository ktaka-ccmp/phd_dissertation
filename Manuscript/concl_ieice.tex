\section{Conclusions}\label{Conclusions}

In this dissertation, the author proposed a portable load balancer with ECMP redundancy for the Kubernetes cluster systems that is aimed at facilitating migration of container clusters for web services.

The author implemented a containerized software load balancer that is run by Kubernetes as a part of container cluster, using Linux kernel's IPVS, as a proof of concept.
In order to discuss the feasibility of the proposed load balancer, we built 
a Kubernetes cluster system and conducted performance measurements.
Our experimental results indicate that the IPVS based load balancer in container improves the portability of 
the Kubernetes cluster system while it shows the similar performance levels as the existing iptables DNAT based load balancer.
We also clarified that choosing the appropriate operating modes of overlay networks is important for the performance of load balancers. 
For example, in the case of flannel, only the vxlan and udp backend operation modes could be used 
in the cloud environment, and the udp backend significantly degraded their performance.
Furthermore, we also learned that the distribution of packet processing among multiple CPUs was very important
to obtain the maximum performance levels from load balancers.

The throughput levels of a load balancer are dependent on settings for multicore packet processing.
It has been better to use as many CPU cores as possible for packet processing.
The throughput levels are also very dependent on the back end mode of the flannel overlay network.
The host-gw mode where no tunneling is used resulted in the best performance level.
It is clear that the case that utilizes all of the CPU cores better performs than the case with only four CPU cores utilized.
The performance levels of ipvs(nat), iptables DNAT and nginx have also been compared.
The proposed ipvs(nat) load balancer in the container had the same performance level as load balancing function of iptables DNAT.
Furthermore in the case of L3DSR setup, the performance level of ipvs(tun) load balancer has about 1.5 times larger that that of ipvs(nat) and iptables DNAT.
It is also shown that the proposed load balancer can be run in GCP and AWS.
The behavior of the proposed load balancer in those cloud environments is the same as that in the on-premise data center.
The author conclude that the proposed load balancer is portable and performs at the same level as the existing load balancers.


The ECMP technique is expected to make the load balancers redundant and scalable since all the load balancer containers act as active.
The whole system is resilient to a single failure of load balancer container.
Also since multiple of load balancers can be utilized simultaneously, it is expected that the throughput of the total system is increased significantly.
In order to evaluate these characteristics of the ECMP technique,
the author examined if the ECMP routing table is updated correctly when multiple of the load balancer {\em pods} are started.
After that, in order to explore the scalability, the author also measured the throughput of the cluster of load balancers.
Finally, the author examined how quick those ECMP routing table updates are.
The author verified that ECMP routing table was properly created in the experimental system.
The update of the ECMP routing table was correct and quick enough, i.e., within 10 seconds, throughout 20 hours experiment.
The scalability of the load balancer was also examined and it has been found that maximum performance levels scaled linearly as the number of the load balancer pods was increased to four.
The maximum throughput level obtained through the experiment was 780k [req/sec], which is limited due to the maximum CPU performance of the benchmark client rather than the performance of the load balancer cluster.

%

The limitations of this work that authors aware of include the followings: 
2) Experiments are conducted only in a 1Gbps network environment.
The experimental results indicate the performance of IPVS may be limited by the network bandwidth, 1Gbps, in our experiments. 
Thus, experiments with the faster network setting, e.g. 10Gigabit ethernet, are needed to investigate the feasibility of the proposed load balancer.

