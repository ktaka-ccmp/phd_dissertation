
Recently, launching web services on cloud computing infrastructure is getting more popular.
Launching web services on the cloud is easier than launching them on on-premise data centers.
A web service on the cloud becomes scalable, which means it can accommodate a large amount of traffic from the Internet by increasing the number of web servers, on demand.
To distribute high volume traffic from the Internet to thousands of web servers load balancers are often used.
Major cloud providers have developed software load balancers\cite{eisenbud2016maglev,patel2013ananta} as part of their infrastructures, which they claim to have a high-performance level and scalability.
In the case of on-premise data centers, one can use proprietary hardware load balancers.
The actual implementation and the performance level of those existing load balancers are very different.

As for another issue regarding web services,
there are also needs to use multiple of cloud providers or on-premise data centers seamlessly, which spread across the world, to prepare for the disaster, to lower the cost or to comply with the legal requirement.
Linux container technology\cite{menage2007adding} facilitates these usages by providing container cluster management system as a middleware,
where one can deploy a web service that consists of a cluster of containers without modification even on different infrastructures.
However, in reality, it is difficult to do so, because existing load balancers are very different and are not included in the container cluster management system.
Therefore, users should always manually adjust their web services to the infrastructure.

In short, there exist several software load balancers that are specific to cloud vendors and on-premise data centers.
The differences among them are the major obstacles to provide uniform container cluster platform, which is necessary to realize web service migration across the different cloud providers and on-premise data centers.

To address this problem, we propose a portable and scalable software load balancer that can be used in any environment including cloud providers and in on-premise data centers.
We can include this load balancer as a part of a container cluster management system, e.g., Kubernetes\cite{K8s2017}, which acts as a common middleware on which web services run.
Users now do not need manual adjustment of their services to the infrastructures.
We will implement the proposed software load balancer using following technologies;
1) To make the load balancer usable in any environment, we containerize ipvs\cite{Zhang2000} using Linux container technology\cite{menage2007adding}.
2) To make the load balancer scalable, we make it capable of being run in parallel using Equal Cost Multi-Path(ECMP) technique\cite{al2008scalable}.
In order to make the load balancer's performance level to meet the need for 10Gbps network speed, a software load balancer that better performs than ipvs is required.
We also implement the novel load balancer using eXpress Data Plane(XDP) technology\cite{bertin2017xdp}.

The outcome of our study will benefit users who want to deploy their web services on any cloud provider where no scalable load balancer is provided, to achieve high scalability.
Moreover, the result of our study will potentially benefit users who want to use a group of different cloud providers and on-premise data centers across the globe, as if it were a single computer on which their web services run.

The rest of the paper is organized as follows.
Section \ref{Related Work} highlights work that deals specifically with container cluster migration, 
software load balancer containerization, and load balancer related tools within the context of the container technology. 
Section \ref{Architecture} will explain existing architecture problems and propose our solutions.
In Section \ref{Experiments}, experimental results for containerized ipvs are discussed,  
which is followed by a summary of our work in Section~\ref{Conclusions}.




